{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, dataset=None, batch_size=1, repeat=1):\n",
    "        if dataset is None:\n",
    "            self.data = [] # generator\n",
    "        else:\n",
    "            self.data = dataset.data\n",
    "        self.__batch_size = batch_size\n",
    "        self.__repeat = repeat\n",
    "        self.__iterator = None\n",
    "        \n",
    "    def map(self, foo):\n",
    "        new_dataset = Dataset(None, self.__batch_size, self.__repeat)\n",
    "        data = [foo(data_point) for data_point in self.data]\n",
    "        return new_dataset\n",
    "    \n",
    "    def batch(self, batch_size):\n",
    "        return Dataset(self, batch_size, self.__repeat)\n",
    "    \n",
    "    def repeat(self, count):\n",
    "        return Dataset(self, self.__batch_size, count)\n",
    "    \n",
    "    def padded_batch(self, batch_size, length, padded_value):\n",
    "        self.data = [item[:length] + [padded_value]*(length - len(item)) for item in data]\n",
    "        new_dataset = Dataset(None, batch_size, self.__repeat)\n",
    "        new_dataset.data = self.data\n",
    "        return new_dataset\n",
    "    \n",
    "    def get_iterator(self):\n",
    "        data_length = len(self.data)\n",
    "        shuffle(self.data)\n",
    "        for i in range(self.__repeat):\n",
    "            for j in range(0, data_length-self.__batch_size+1, self.__batch_size):\n",
    "                start = j\n",
    "                end = j+self.__batch_size\n",
    "                yield self.data[j: j+self.__batch_size]\n",
    "\n",
    "    @staticmethod    \n",
    "    def fromCsv(filename, columns=None):\n",
    "        df = pd.read_csv(filename)\n",
    "        if isinstance(columns, list):\n",
    "            datas = [list(df[col]) for col in columns]\n",
    "        else:\n",
    "            datas = [list(df[col]) for col in df.columns]\n",
    "        new_dataset = Dataset()\n",
    "        new_dataset.data = list(zip(*datas))\n",
    "        return new_dataset\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_tensor_slices(tensors):\n",
    "        assert isinstance(tensors, tuple)\n",
    "        new_dataset = Dataset()\n",
    "        new_dataset.data = list(zip(*tensors))\n",
    "        return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTROPY_PATH = os.path.join('/dataset', 'entropy_2018')\n",
    "TRAINING_PATH = os.path.join(ENTROPY_PATH, 'training_set.csv')\n",
    "TEST_PATH = os.path.join(ENTROPY_PATH, 'test_set.csv')\n",
    "\n",
    "dataset = Dataset.fromCsv(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_tensor_slices((data,))\n",
    "# dataset = Dataset.fromCsv(TRAINING_PATH, ['sentiment', 'sentence'])\n",
    "# dataset = dataset.padded_batch(2, 2, -1)\n",
    "dataset = dataset.batch(5)\n",
    "# dataset = dataset.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.get_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quá tệ! Lỗi liên tục.', 'negative'),\n",
       " ('Thương chú Đại Nghĩa ghê hông nè...?? Các bạn trong tập 8 xuất sắc quá nên chú Đại Nghĩa phải đau đầu luôn rồi. :D :D ------ Người Hùng Tí Hon tập 8 phát sóng vào lúc 19h, ngày 10/09 trên HTV7. ------- Người Hùng Tí Hon mùa 2 cám ơn sự đồng hành của Chuyên gia selfie - OPPO Camera Phone F1s Timeline Photos',\n",
       "  'neutral'),\n",
       " ('Quá đẹp luôn anh Lê Hữu Thuận :)', 'positive'),\n",
       " ('Chào bạn Ngọc Hân Phạm. Bộ sưu tập của bạn đã hợp lệ. Bạn vui lòng gửi thẻ về cho chương trình theo hướng dẫn sau. Người tham dự cần gửi 05 thẻ Doraemon này về địa chỉ văn phòng đại diện nhãn hàng Ovaltine - Công ty TNHH Tiếp Thị Ứng Dụng Thông Thái tại 242 Cống Quỳnh - (lầu 3) Tòa nhà SCB, Phường Phạm Ngũ Lão, Quận 1, TP. Hồ Chí Minh trước ngày 10/02/2017. Bên trong bì thư ghi rõ thông tin chi tiết gồm: Họ và tên, Số điện thoại, Địa chỉ. Người chơi sử dụng mã 70C-0217-049SG (*) hoặc OVALTINE-049SG (**) để được gửi miễn phí thông qua hệ thống Bưu điện Việt Nam.',\n",
       "  'neutral'),\n",
       " ('Thế sang đung messenger trên facebook còn hơn . Lạy ???????????? chiêu trò hết của Viettel thôi. Mình xài vina nhiều gói ưu đãi hơn nên thích dùng vina',\n",
       "  'negative')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Anh Phi nhìn chảy nc miếng', 'neutral')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentiment', 'sentence']\n",
    "df = pd.read_csv(TRAINING_PATH)\n",
    "if isinstance(columns, list):\n",
    "    datas = [list(df[col] for col in columns]\n",
    "else:\n",
    "    datas = [df[col] for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(['a', 'b'], [1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.ipynb  main.ipynb\t start-tensorboard.sh  text2vec.p\r\n",
      "doc2vec.ipynb  start-jupyter.sh  summary\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
